{"cells":[{"cell_type":"markdown","source":["# Machine failure prediction"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8cd50c2a-35ab-455b-ae73-5d849e60d20f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Introduction\n\nIn the field of industrial maintenance and operations, the timely detection of machine failures is crucial to prevent unexpected downtime, minimize production losses, and optimize maintenance strategies. Machine learning techniques have emerged as valuable tools for predicting and classifying data. However, the effectiveness of such models heavily relies on the quality and balance of the dataset used for training.\n\nThroughout this project, I will explore different techniques for addressing class imbalance, including oversampling and undersampling methods, such as Synthetic Minority Over-sampling Technique (SMOTE) and Random Under-Sampling (RUS). Additionally, I will investigate the impact of various feature engineering strategies, such as dimensionality reduction and feature selection, to improve the model's ability to discriminate between healthy and failing machines.\n\nThe performance of the developed binary classification models will be evaluated using accuracy, consufion matrix and area under the receiver operating characteristic curve (AUC-ROC). The results will be compared with a baseline model trained on the original unbalanced dataset, highlighting the effectiveness of the proposed techniques in improving the model's performance on the minority class (failure machines)."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"96816ed7-b08a-4ca3-abb9-f99880c3535d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!pip install imbalanced-learn\n!pip install deepchecks --upgrade"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0dbf0cd1-b39f-4b06-960d-2445366aa2a6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Loading the train data uploaded to Databricks previously"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"45a68f04-9919-4055-9c57-9248337b973d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def load_datasets(files_location, file_type):\n    for file_location in files_location:\n        # CSV options\n        infer_schema = \"false\"\n        first_row_is_header = \"true\"\n        delimiter = \",\"\n\n        # The applied options are for CSV files. For other file types, these will be ignored.\n        df = spark.read.format(file_type) \\\n        .option(\"inferSchema\", infer_schema) \\\n        .option(\"header\", first_row_is_header) \\\n        .option(\"sep\", delimiter) \\\n        .load(file_location)\n        yield df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6482be4c-f067-47c9-b0ac-35c938b94601","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# File location and type\nfiles_location = [\"/FileStore/tables/train.csv\", \"/FileStore/tables/test.csv\"]\nfile_type = \"csv\"\n\ntrain, test = load_datasets(files_location, file_type)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ce5c2064-293b-4d14-9f3a-78efa6bdeb68","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"code","source":["train.limit(5).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2679f3fe-1ad4-4772-b3e9-e03327d262d3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"code","source":["test.limit(5).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a0f656ac-907a-47d1-935a-eeef8c0142e1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Standardization of columns name"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1511c203-a678-43c2-9321-0d918f3c361f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_replace, col\n\ndef rename_lower_columns(dfs):\n    for df in dfs:\n        # Rename columns with spaces to columns with underscores\n        df = df.withColumnRenamed(\"Product Id\", \"product_id\")\\\n                .withColumnRenamed(\"Air temperature [K]\", \"air_temperature\")\\\n                .withColumnRenamed(\"Process temperature [K]\", \"process_temperature\")\\\n                .withColumnRenamed(\"Rotational speed [rpm]\", \"rotational_speed\")\\\n                .withColumnRenamed(\"Torque [Nm]\", \"torque\")\\\n                .withColumnRenamed(\"Tool wear [min]\", \"tool_wear\")\\\n                .withColumnRenamed(\"machine failure\", \"machine_failure\")\n\n        # Lower all columns name\n        df = df.select([c.lower() for c in df.columns])\n\n        # Remove unwanted characters from columns name\n        df = df.select([regexp_replace(col(c), \"[ ,;{}()\\n\\t=]\", \"\").alias(c) for c in df.columns])\n        yield df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e5b39639-2fd6-4e75-8eff-bddef9f900d8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"code","source":["train, test = rename_lower_columns([train, test])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0bbbb066-fd44-46d8-a2af-70f8a6313941","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"code","source":["train.limit(5).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6aa9eef5-6da5-45a8-8b43-86e4eef00859","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Saving data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"977328a8-03bf-41d5-9772-a14178c2c9ca","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Save table\n\nspark.sql(\"DROP TABLE IF EXISTS train_csv\")\nspark.sql(\"DROP TABLE IF EXISTS test_csv\")\n\ntrain.write.mode(\"overwrite\").option(\"header\", \"true\").option(\"overwriteSchema\", \"True\").format(\"csv\")\\\n    .option(\"path\", \"/tables/train\")\\\n    .saveAsTable(\"train\")\n\ntest.write.mode(\"overwrite\").option(\"header\", \"true\").option(\"overwriteSchema\", \"True\").format(\"csv\")\\\n    .option(\"path\", \"/tables/test\")\\\n    .saveAsTable(\"test\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"db9631f6-bb4a-42ca-8a3c-0d48af932331","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Exploratory Data Analysis"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f373f452-602c-47dd-9be1-a54866c6204f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Loading the table using Apache Spark SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"06ca5e43-d5de-415a-9dda-2e7a01d13c72","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\n\nCREATE OR REPLACE TABLE train_table\nUSING DELTA LOCATION \"/tables/train_data\"\nAS (\n  SELECT\n    first(type) AS type,\n    first(machine_failure) AS machine_failure,\n    MAX(CAST(air_temperature AS INT)) AS max_air_temperature,\n    MIN(CAST(air_temperature AS INT)) AS min_air_temperature,\n    AVG(CAST(air_temperature AS INT)) AS avg_air_temperature,\n    MAX(CAST(process_temperature AS INT)) AS max_process_temperature,\n    MIN(CAST(process_temperature AS INT)) AS min_process_temperature,\n    AVG(CAST(process_temperature AS INT)) AS avg_process_temperature,\n    MAX(CAST(rotational_speed AS INT)) AS max_rotational_speed,\n    MIN(CAST(rotational_speed AS INT)) AS min_rotational_speed,\n    AVG(CAST(rotational_speed AS INT)) AS avg_rotational_speed,\n    MAX(CAST(torque AS INT)) AS max_torque,\n    MIN(CAST(torque AS INT)) AS min_torque,\n    AVG(CAST(torque AS INT)) AS avg_torque,\n    MAX(CAST(tool_wear AS INT)) AS max_tool_wear,\n    MIN(CAST(tool_wear AS INT)) AS min_tool_wear,\n    AVG(CAST(tool_wear AS INT)) AS avg_tool_wear\n  FROM train\n  GROUP BY product_id\n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"612a8b95-d218-4108-ae82-3fa44f479926","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m/usr/lib/python3.10/pathlib.py:625\u001B[0m, in \u001B[0;36mPurePath.__str__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 625\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_str\u001B[49m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\n\u001B[0;31mAttributeError\u001B[0m: 'PosixPath' object has no attribute '_str'\n\nDuring handling of the above exception, another exception occurred:\n\n\u001B[0;31mRecursionError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-2800313163698086>:6\u001B[0m\n\u001B[1;32m      4\u001B[0m     display(df)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 6\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m __databricks_percent_sql()\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      8\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m __databricks_percent_sql\n\nFile \u001B[0;32m<command-2800313163698086>:3\u001B[0m, in \u001B[0;36m__databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__databricks_percent_sql\u001B[39m():\n\u001B[0;32m----> 3\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43m__import__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpyspark\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdbutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentry_point\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetImplicitDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msqlContext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m   display(df)\n\u001B[1;32m      5\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:149\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, jdf, sql_ctx)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sql_ctx, SQLContext)\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# We should remove this if-else branch in the future release, and rename\u001B[39;00m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;66;03m# sql_ctx to session in the constructor. This is an internal code path but\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;66;03m# was kept with a warning because it's used intensively by third-party libraries.\u001B[39;00m\n\u001B[0;32m--> 149\u001B[0m \u001B[43mwarnings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDataFrame constructor is internal. Do not directly use it.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sql_ctx \u001B[38;5;241m=\u001B[39m sql_ctx\n\u001B[1;32m    151\u001B[0m session \u001B[38;5;241m=\u001B[39m sql_ctx\u001B[38;5;241m.\u001B[39msparkSession\n\nFile \u001B[0;32m/usr/lib/python3.10/warnings.py:109\u001B[0m, in \u001B[0;36m_showwarnmsg\u001B[0;34m(msg)\u001B[0m\n\u001B[1;32m    105\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(sw):\n\u001B[1;32m    106\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarnings.showwarning() must be set to a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    107\u001B[0m                             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction or method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 109\u001B[0m         \u001B[43msw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m           \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    112\u001B[0m _showwarnmsg_impl(msg)\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:72\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMLflow autologging encountered a warning: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     66\u001B[0m         filename,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     69\u001B[0m         message,\n\u001B[1;32m     70\u001B[0m     )\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_original_showwarning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:72\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMLflow autologging encountered a warning: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     66\u001B[0m         filename,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     69\u001B[0m         message,\n\u001B[1;32m     70\u001B[0m     )\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_original_showwarning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\n    \u001B[0;31m[... skipping similar frames: _WarningsController._patched_showwarning at line 72 (2959 times)]\u001B[0m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:72\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMLflow autologging encountered a warning: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     66\u001B[0m         filename,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     69\u001B[0m         message,\n\u001B[1;32m     70\u001B[0m     )\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_original_showwarning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:53\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautologging_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _logger\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# If the warning's source file is contained within the MLflow package's base\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# directory, it is an MLflow warning and should be emitted via `logger.warning`\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m warning_source_path \u001B[38;5;241m=\u001B[39m \u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m is_mlflow_warning \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mlflow_root_path \u001B[38;5;129;01min\u001B[39;00m warning_source_path\u001B[38;5;241m.\u001B[39mparents\n\u001B[1;32m     55\u001B[0m curr_thread \u001B[38;5;241m=\u001B[39m get_current_thread_id()\n\nFile \u001B[0;32m/usr/lib/python3.10/pathlib.py:1077\u001B[0m, in \u001B[0;36mPath.resolve\u001B[0;34m(self, strict)\u001B[0m\n\u001B[1;32m   1074\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSymlink loop from \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m e\u001B[38;5;241m.\u001B[39mfilename)\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1077\u001B[0m     s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrealpath\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1079\u001B[0m     check_eloop(e)\n\nFile \u001B[0;32m/usr/lib/python3.10/posixpath.py:394\u001B[0m, in \u001B[0;36mrealpath\u001B[0;34m(filename, strict)\u001B[0m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrealpath\u001B[39m(filename, \u001B[38;5;241m*\u001B[39m, strict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    392\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the canonical path of the specified filename, eliminating any\u001B[39;00m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;124;03msymbolic links encountered in the path.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 394\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    395\u001B[0m     path, ok \u001B[38;5;241m=\u001B[39m _joinrealpath(filename[:\u001B[38;5;241m0\u001B[39m], filename, strict, {})\n\u001B[1;32m    396\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m abspath(path)\n\nFile \u001B[0;32m/usr/lib/python3.10/pathlib.py:632\u001B[0m, in \u001B[0;36mPurePath.__fspath__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__fspath__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/usr/lib/python3.10/pathlib.py:627\u001B[0m, in \u001B[0;36mPurePath.__str__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_str\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m--> 627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format_parsed_parts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_root\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m                                          \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parts\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_str\n\nFile \u001B[0;32m/usr/lib/python3.10/pathlib.py:611\u001B[0m, in \u001B[0;36mPurePath._format_parsed_parts\u001B[0;34m(cls, drv, root, parts)\u001B[0m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    609\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_format_parsed_parts\u001B[39m(\u001B[38;5;28mcls\u001B[39m, drv, root, parts):\n\u001B[1;32m    610\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drv \u001B[38;5;129;01mor\u001B[39;00m root:\n\u001B[0;32m--> 611\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m drv \u001B[38;5;241m+\u001B[39m root \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flavour\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    612\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_flavour\u001B[38;5;241m.\u001B[39mjoin(parts)\n\n\u001B[0;31mRecursionError\u001B[0m: maximum recursion depth exceeded while calling a Python object","errorSummary":"<span class='ansi-red-fg'>RecursionError</span>: maximum recursion depth exceeded while calling a Python object","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n","\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n","File \u001B[0;32m/usr/lib/python3.10/pathlib.py:625\u001B[0m, in \u001B[0;36mPurePath.__str__\u001B[0;34m(self)\u001B[0m\n","\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n","\u001B[0;32m--> 625\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_str\u001B[49m\n","\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n","\n","\u001B[0;31mAttributeError\u001B[0m: 'PosixPath' object has no attribute '_str'\n","\n","During handling of the above exception, another exception occurred:\n","\n","\u001B[0;31mRecursionError\u001B[0m                            Traceback (most recent call last)\n","File \u001B[0;32m<command-2800313163698086>:6\u001B[0m\n","\u001B[1;32m      4\u001B[0m     display(df)\n","\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n","\u001B[0;32m----> 6\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m __databricks_percent_sql()\n","\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n","\u001B[1;32m      8\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m __databricks_percent_sql\n","\n","File \u001B[0;32m<command-2800313163698086>:3\u001B[0m, in \u001B[0;36m__databricks_percent_sql\u001B[0;34m()\u001B[0m\n","\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__databricks_percent_sql\u001B[39m():\n","\u001B[0;32m----> 3\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43m__import__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpyspark\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdbutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentry_point\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetImplicitDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msqlContext\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m      4\u001B[0m   display(df)\n","\u001B[1;32m      5\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n","\n","File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n","\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n","\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n","\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n","\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n","\u001B[1;32m     51\u001B[0m     )\n","\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n","\n","File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:149\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, jdf, sql_ctx)\u001B[0m\n","\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sql_ctx, SQLContext)\n","\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# We should remove this if-else branch in the future release, and rename\u001B[39;00m\n","\u001B[1;32m    147\u001B[0m \u001B[38;5;66;03m# sql_ctx to session in the constructor. This is an internal code path but\u001B[39;00m\n","\u001B[1;32m    148\u001B[0m \u001B[38;5;66;03m# was kept with a warning because it's used intensively by third-party libraries.\u001B[39;00m\n","\u001B[0;32m--> 149\u001B[0m \u001B[43mwarnings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwarn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDataFrame constructor is internal. Do not directly use it.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n","\u001B[1;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sql_ctx \u001B[38;5;241m=\u001B[39m sql_ctx\n","\u001B[1;32m    151\u001B[0m session \u001B[38;5;241m=\u001B[39m sql_ctx\u001B[38;5;241m.\u001B[39msparkSession\n","\n","File \u001B[0;32m/usr/lib/python3.10/warnings.py:109\u001B[0m, in \u001B[0;36m_showwarnmsg\u001B[0;34m(msg)\u001B[0m\n","\u001B[1;32m    105\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(sw):\n","\u001B[1;32m    106\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarnings.showwarning() must be set to a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n","\u001B[1;32m    107\u001B[0m                             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction or method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n","\u001B[0;32m--> 109\u001B[0m         \u001B[43msw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\n","\u001B[1;32m    110\u001B[0m \u001B[43m           \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m    111\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n","\u001B[1;32m    112\u001B[0m _showwarnmsg_impl(msg)\n","\n","File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:72\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n","\u001B[1;32m     64\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\n","\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMLflow autologging encountered a warning: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m,\n","\u001B[1;32m     66\u001B[0m         filename,\n","\u001B[0;32m   (...)\u001B[0m\n","\u001B[1;32m     69\u001B[0m         message,\n","\u001B[1;32m     70\u001B[0m     )\n","\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n","\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_original_showwarning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n","\n","File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:72\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n","\u001B[1;32m     64\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\n","\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMLflow autologging encountered a warning: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m,\n","\u001B[1;32m     66\u001B[0m         filename,\n","\u001B[0;32m   (...)\u001B[0m\n","\u001B[1;32m     69\u001B[0m         message,\n","\u001B[1;32m     70\u001B[0m     )\n","\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n","\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_original_showwarning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n","\n","    \u001B[0;31m[... skipping similar frames: _WarningsController._patched_showwarning at line 72 (2959 times)]\u001B[0m\n","\n","File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:72\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n","\u001B[1;32m     64\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\n","\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMLflow autologging encountered a warning: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m,\n","\u001B[1;32m     66\u001B[0m         filename,\n","\u001B[0;32m   (...)\u001B[0m\n","\u001B[1;32m     69\u001B[0m         message,\n","\u001B[1;32m     70\u001B[0m     )\n","\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n","\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_original_showwarning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n","\n","File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/utils/autologging_utils/logging_and_warnings.py:53\u001B[0m, in \u001B[0;36m_WarningsController._patched_showwarning\u001B[0;34m(self, message, category, filename, lineno, *args, **kwargs)\u001B[0m\n","\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautologging_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _logger\n","\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# If the warning's source file is contained within the MLflow package's base\u001B[39;00m\n","\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# directory, it is an MLflow warning and should be emitted via `logger.warning`\u001B[39;00m\n","\u001B[0;32m---> 53\u001B[0m warning_source_path \u001B[38;5;241m=\u001B[39m \u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m     54\u001B[0m is_mlflow_warning \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mlflow_root_path \u001B[38;5;129;01min\u001B[39;00m warning_source_path\u001B[38;5;241m.\u001B[39mparents\n","\u001B[1;32m     55\u001B[0m curr_thread \u001B[38;5;241m=\u001B[39m get_current_thread_id()\n","\n","File \u001B[0;32m/usr/lib/python3.10/pathlib.py:1077\u001B[0m, in \u001B[0;36mPath.resolve\u001B[0;34m(self, strict)\u001B[0m\n","\u001B[1;32m   1074\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSymlink loop from \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m e\u001B[38;5;241m.\u001B[39mfilename)\n","\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n","\u001B[0;32m-> 1077\u001B[0m     s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrealpath\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n","\u001B[1;32m   1079\u001B[0m     check_eloop(e)\n","\n","File \u001B[0;32m/usr/lib/python3.10/posixpath.py:394\u001B[0m, in \u001B[0;36mrealpath\u001B[0;34m(filename, strict)\u001B[0m\n","\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrealpath\u001B[39m(filename, \u001B[38;5;241m*\u001B[39m, strict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n","\u001B[1;32m    392\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the canonical path of the specified filename, eliminating any\u001B[39;00m\n","\u001B[1;32m    393\u001B[0m \u001B[38;5;124;03msymbolic links encountered in the path.\"\"\"\u001B[39;00m\n","\u001B[0;32m--> 394\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m    395\u001B[0m     path, ok \u001B[38;5;241m=\u001B[39m _joinrealpath(filename[:\u001B[38;5;241m0\u001B[39m], filename, strict, {})\n","\u001B[1;32m    396\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m abspath(path)\n","\n","File \u001B[0;32m/usr/lib/python3.10/pathlib.py:632\u001B[0m, in \u001B[0;36mPurePath.__fspath__\u001B[0;34m(self)\u001B[0m\n","\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__fspath__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n","\u001B[0;32m--> 632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n","\n","File \u001B[0;32m/usr/lib/python3.10/pathlib.py:627\u001B[0m, in \u001B[0;36mPurePath.__str__\u001B[0;34m(self)\u001B[0m\n","\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_str\n","\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n","\u001B[0;32m--> 627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format_parsed_parts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_root\u001B[49m\u001B[43m,\u001B[49m\n","\u001B[1;32m    628\u001B[0m \u001B[43m                                          \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parts\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\n","\u001B[1;32m    629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_str\n","\n","File \u001B[0;32m/usr/lib/python3.10/pathlib.py:611\u001B[0m, in \u001B[0;36mPurePath._format_parsed_parts\u001B[0;34m(cls, drv, root, parts)\u001B[0m\n","\u001B[1;32m    608\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n","\u001B[1;32m    609\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_format_parsed_parts\u001B[39m(\u001B[38;5;28mcls\u001B[39m, drv, root, parts):\n","\u001B[1;32m    610\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drv \u001B[38;5;129;01mor\u001B[39;00m root:\n","\u001B[0;32m--> 611\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m drv \u001B[38;5;241m+\u001B[39m root \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flavour\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m    612\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n","\u001B[1;32m    613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_flavour\u001B[38;5;241m.\u001B[39mjoin(parts)\n","\n","\u001B[0;31mRecursionError\u001B[0m: maximum recursion depth exceeded while calling a Python object"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Using the DESCRIBE function to output table details such as data type**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6afaa0fc-358d-4125-8ce0-ff67b506ea23","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\n-- Print details \nDESCRIBE EXTENDED train_table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"71163cdc-a856-4f84-8df9-4cd349839d68","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\n-- Select the first 10 rows\nSELECT * \nFROM train_table\nLIMIT 10"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"c50fe658-dcf5-4c7a-b457-bac6195c2358","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\n-- plot total by machine type\nSELECT type, count(*) AS total\nFROM train_table\nGROUP BY type"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"ff71bd55-78e5-477f-828e-6a5e6e86aa38","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["This plot displays the distribution of machine types based on the total number of machines. Ideally, we aim for a relatively balanced distribution across all machine types. Having a similar number of machines for each type ensures that our model is not biased or overly influenced by the machine type feature."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8a3bfdbc-0ced-41ba-b36b-a930038b3b58","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql \n\n-- plot total by machine status (failure or not)\nSELECT type, machine_failure, COUNT(*) AS total\nFROM train_table\nGROUP BY type, machine_failure"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"7426f32c-d0b0-46a3-86cf-bde07cb877eb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["This plot reveals an important insight: the failure percentage does not exceed 2% for any machine type. This information indicates that our dataset is unbalanced, as there is a significant difference in the failure occurrences across machine types. From a modeling perspective, it is crucial to address this class imbalance issue to ensure that it does not adversely impact the model's performance."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"89961c07-a85b-4a09-896d-9aca6bdcb840","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Modeling"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"535b73a5-153d-4909-8eac-81a7058f44da","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**Benchmark Model**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6261d7a4-f0a8-40f2-995c-bb401dda46fb","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# read table \ndf = spark.table(\"train_table\").toPandas()\ndf.head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c36aef87-f08b-44e9-b46e-9968c62af3f3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, roc_auc_score, ConfusionMatrixDisplay, RocCurveDisplay, roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelBinarizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.compose import ColumnTransformer\n\ny_scores = []\n\nX = df.drop(\"machine_failure\", axis=1)\ny = df[\"machine_failure\"]\n\n# Split data into train and validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n\n# Preprocess categorical and numerical features separately\ncategorical_features = ['type']\nnumerical_features = df.drop([\"type\", \"machine_failure\"], axis=1).columns\n\n# Create transformers for each feature type\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(), categorical_features),\n        ('num', StandardScaler(), numerical_features)\n    ])\n\n# Create a pipeline\nbenchmark = make_pipeline(preprocessor, LogisticRegression())\n\n# Fit the pipeline to the train set\nbenchmark.fit(X_train, y_train)\n\n# Compute probabilities\ny_score = benchmark.predict_proba(X_val)\ny_scores.append(y_score)\n\n# Compute the accuracy score in the validation set\nprint(benchmark.score(X, y))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7d357751-bcdd-4277-998b-30053e394f0b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["The accuracy value achieved is remarkably high, with nearly 100% correct predictions. However, it is crucial to address a significant issue that has been mentioned previously. The dataset suffers from a severe class imbalance, with 98% of cases representing non-failure instances. Consequently, our model might struggle to identify failure cases effectively, as there is a 98% chance that simply predicting that a machine is not failing would yield correct results by chance. Now let's look to the AUC ROC curve and the confusion matrix as these metrics can shows a more accurate result.\n\nTo gain a more comprehensive understanding of our model's performance, it is recommended to use metrics such as the AUC ROC curve and the confusion matrix. These metrics provide a more accurate assessment of the model's predictive ability, particularly in scenarios with imbalanced datasets. By examining these metrics, we can better evaluate how well our model distinguishes between failure and non-failure cases."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"885d27e6-3d1d-4e29-a9c8-7d41fad29887","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["RocCurveDisplay.from_estimator(benchmark, X, y)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e9ef0e68-021a-4fbb-9398-2614f1957c47","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Oops! It appears that the AUC ROC curve reveals a different story compared to the initially high accuracy. The plot indicates that our model's performance is not as impressive as the accuracy metric initially suggested. In fact, the AUC ROC curve indicates that our model was able to correctly classify only 77% of the cases. Now let's use the confusion matrix to further investigate what is happening with our model's performance."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c2acdf10-a764-4b2c-bb5d-654bf1108cfe","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["ConfusionMatrixDisplay.from_estimator(benchmark, X, y)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8447f765-81c9-411f-886d-fa5da26a9b93","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Finally, we have uncovered the truth about our model's performance. Upon closer examination, it becomes evident that our model excelled in classifying non-failure machines. However, when it comes to identifying failure cases, our model fared poorly, failing to correctly classify even a single instance of failure machines.\n\nIt is imperative to address the significant imbalance between failure and non-failure cases in our dataset, as any misclassification could have severe consequences. We must now focus on improving our model's ability to accurately identify and classify failure instances, as it is a critical aspect of our application."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"359481c8-bdf1-4f82-a8c9-7c9da13bad9e","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Bootstrap sample the minority class\n\nRandomly duplicate examples in the minority class by sampling with replacement"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0426474e-179e-4a9f-aad4-3219109f1f4c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from imblearn.over_sampling import RandomOverSampler\n\noversample = RandomOverSampler(sampling_strategy='minority')\n\nX_over, y_over = oversample.fit_resample(X, y)\n\nprint(f\"Result: {y_over.value_counts()/len(y_over)}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4dc05d45-93c4-41d4-9431-5d4a3b4d3789","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["# Split data into train and validation\nX_train, X_val, y_train, y_val = train_test_split(X_over, y_over, test_size=0.10, random_state=42)\n\n# Preprocess categorical and numerical features separately\ncategorical_features = ['type']\nnumerical_features = df.drop([\"type\", \"machine_failure\"], axis=1).columns\n\n# Create transformers for each feature type\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(), categorical_features),\n        ('num', StandardScaler(), numerical_features)\n    ])\n\n# Create a pipeline\npipeline_over = make_pipeline(preprocessor, LogisticRegression())\n\n# Fit the pipeline to the train set\npipeline_over.fit(X_train, y_train)\n\n# Compute probabilities\ny_score = pipeline_over.predict_proba(X_val)\ny_scores.append(y_score)\n\n# Compute the accuracy score in the validation set\nprint(pipeline_over.score(X, y))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9c1de76a-68b8-4641-9dca-9ce270fa1317","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Undersample the majority class\n\nRandomly delete examples from the majority class"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"60936e10-aa73-4e5f-9a53-536494cb0fea","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from imblearn.under_sampling import RandomUnderSampler\n\nundersample = RandomUnderSampler(sampling_strategy='majority')\n\nX_under, y_under = undersample.fit_resample(X, y)\n\nprint(f\"Result: {y_under.value_counts()/len(y_under)}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"41b465c3-bc71-4a04-89db-9538cbf39af4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["# Split data into train and validation\nX_train, X_val, y_train, y_val = train_test_split(X_under, y_under, test_size=0.10, random_state=42)\n\n# Preprocess categorical and numerical features separately\ncategorical_features = ['type']\nnumerical_features = df.drop([\"type\", \"machine_failure\"], axis=1).columns\n\n# Create transformers for each feature type\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(), categorical_features),\n        ('num', StandardScaler(), numerical_features)\n    ])\n\n# Create a pipeline\npipeline_under = make_pipeline(preprocessor, LogisticRegression())\n\n# Fit the pipeline to the train set\npipeline_under.fit(X_train, y_train)\n\n# Predict the validation set\ny_predicted = pipeline_under.predict(X_val)\n\n# Compute probabilities\ny_score = pipeline_under.predict_proba(X_val)\ny_scores.append(y_score)\n\n# Compute the accuracy score in the validation set\nprint(pipeline_under.score(X, y))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b750885f-0d3c-4b57-84f6-02dfba540891","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["By using oversampling and undersampling we had a worst accuracy score we before we need to look at others metrics such as confusion matrix and AUC."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"33422c6b-400c-4bb7-89ec-8b64d545920f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\nmodels_name = [\"Benchmark\", \"Oversample\", \"Undersample\"] \nfor model, name in zip([benchmark, pipeline_over, pipeline_under], models_name):\n    RocCurveDisplay.from_estimator(model, X, y, name=name)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"dc4051c9-b1a0-4db1-a106-01a9413f9817","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["models_name = [\"Benchmark\", \"Oversample\", \"Undersample\"] \nfor model, name in zip([benchmark, pipeline_over, pipeline_under], models_name):\n    ConfusionMatrixDisplay.from_estimator(model, X, y)\n    plt.title(name)\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a7133a52-25ec-4e77-8288-17884ff600fe","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## SMOTE"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b160a122-8e04-431f-86d6-0ffd3824b6ca","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Machine Failure Prediction","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2800313163698095,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
